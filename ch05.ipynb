{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "cb_Q4W8Dt3tm"
      },
      "source": [
        "[[ch05]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Ajh-qot3tm"
      },
      "source": [
        "# Embeddings: How Machines \"Understand\" Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbXkcsust3tn"
      },
      "source": [
        "## Understand vs. Reading Text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安装依赖FOR GOOGLE COLAB11"
      ],
      "metadata": {
        "id": "pRbPzbJzufR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 原因：torchtext不再维护\n"
      ],
      "metadata": {
        "id": "JVWF4s7yaz8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "原因：（最新torchtext版本为0.18.0，对应的torch版本为2.3.0）\n",
        "但google colab上 torch版本为2.5.1+cu121\n",
        "所以会出现载入 torchtext失败的问题\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N1xYCmemcHyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "最新torchtext版本为0.18.0，对应的torch版本为2.3.0\n",
        "发现有问题，torchtext0.18.0太新了，代码中有些函数现在已经不用了\n"
      ],
      "metadata": {
        "id": "edbIIZV82fX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuwwqX0mXcbv",
        "outputId": "3566ca3c-8365-4a09-d16a-516e7e3477c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.5.1+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pytorch和torchtext的对应兼容版本见：**\n",
        "\n",
        "https://github.com/pytorch/text/\n",
        "\n"
      ],
      "metadata": {
        "id": "mILq9h6i4PeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 尝试1：更换回老的pytorch和torchtext版本，各种兼容性问题，放弃\n"
      ],
      "metadata": {
        "id": "4Iej6ZDa2oAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtWiIKFjYHw2",
        "outputId": "cb1fb868-bdbb-42c6-c562-68086d712ba3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.11/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch-2.5.1+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torch==2.3.0\n",
        "!pip install torch==1.13.0\n",
        "#torch==1.5.0 torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcsZGHMtYZLB",
        "outputId": "b596917b-1f3e-431d-aceb-ccf130639624"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.45.1)\n",
            "Downloading torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torchtext==0.18.0\n",
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pFVDcpuYsld",
        "outputId": "723f523c-4368-454a-d854-32524cf842bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (1.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchtext==0.6.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchtext==0.6.0) (0.45.1)\n",
            "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 尝试2：安装conda, 但conda无法创建新的env，只能使用默认的env\n",
        "尝试退回到老的torchtext和torch版本，需要使用python3.8环境\n",
        "但创建python3.8新环境无法使用\n",
        "\n",
        "**google colab环境中搭建conda环境见：**\n",
        "\n",
        "\n",
        "https://saturncloud.io/blog/\n",
        "\n",
        "how-to-install-conda-package-to-google-colab/\n",
        "https://pypi.org/project/condacolab/\n",
        "\n"
      ],
      "metadata": {
        "id": "d4YayVRl0tGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab"
      ],
      "metadata": {
        "id": "UYLdSNjsgdEx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmUrtgJxiECz",
        "outputId": "e58ce963-c0d6-419c-921a-3fa092dd89dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:17\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "PVntrbz2upMI",
        "outputId": "a87d8c06-78a3-459b-cb15-e4f41253cd49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda list"
      ],
      "metadata": {
        "id": "D-Gx5U7buw8y",
        "outputId": "eab18853-b87a-4e74-88a1-be291d2b1845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# packages in environment at /usr/local:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
            "_openmp_mutex             4.5                       2_gnu    conda-forge\n",
            "archspec                  0.2.3              pyhd8ed1ab_0    conda-forge\n",
            "boltons                   24.0.0             pyhd8ed1ab_1    conda-forge\n",
            "brotli-python             1.1.0           py311hfdbb021_2    conda-forge\n",
            "bzip2                     1.0.8                h4bc722e_7    conda-forge\n",
            "c-ares                    1.34.4               hb9d3cd8_0    conda-forge\n",
            "ca-certificates           2024.12.14           hbcca054_0    conda-forge\n",
            "certifi                   2024.12.14         pyhd8ed1ab_0    conda-forge\n",
            "cffi                      1.17.1          py311hf29c0ef_0    conda-forge\n",
            "charset-normalizer        3.4.1              pyhd8ed1ab_0    conda-forge\n",
            "colorama                  0.4.6              pyhd8ed1ab_1    conda-forge\n",
            "conda                     24.11.2         py311h38be061_1    conda-forge\n",
            "conda-libmamba-solver     24.9.0             pyhd8ed1ab_0    conda-forge\n",
            "conda-package-handling    2.4.0              pyh7900ff3_2    conda-forge\n",
            "conda-package-streaming   0.11.0             pyhd8ed1ab_0    conda-forge\n",
            "distro                    1.9.0              pyhd8ed1ab_1    conda-forge\n",
            "fmt                       11.0.2               h434a139_0    conda-forge\n",
            "frozendict                2.4.6           py311h9ecbd09_0    conda-forge\n",
            "h2                        4.1.0              pyhd8ed1ab_1    conda-forge\n",
            "hpack                     4.0.0              pyhd8ed1ab_1    conda-forge\n",
            "hyperframe                6.0.1              pyhd8ed1ab_1    conda-forge\n",
            "idna                      3.10               pyhd8ed1ab_1    conda-forge\n",
            "jsonpatch                 1.33               pyhd8ed1ab_1    conda-forge\n",
            "jsonpointer               3.0.0           py311h38be061_1    conda-forge\n",
            "keyutils                  1.6.1                h166bdaf_0    conda-forge\n",
            "krb5                      1.21.3               h659f571_0    conda-forge\n",
            "ld_impl_linux-64          2.43                 h712a8e2_2    conda-forge\n",
            "libarchive                3.7.7                h4585015_3    conda-forge\n",
            "libcurl                   8.11.1               h332b0f4_0    conda-forge\n",
            "libedit                   3.1.20240808    pl5321h7949ede_0    conda-forge\n",
            "libev                     4.33                 hd590300_2    conda-forge\n",
            "libexpat                  2.6.4                h5888daf_0    conda-forge\n",
            "libffi                    3.4.2                h7f98852_5    conda-forge\n",
            "libgcc                    14.2.0               h77fa898_1    conda-forge\n",
            "libgcc-ng                 14.2.0               h69a702a_1    conda-forge\n",
            "libgomp                   14.2.0               h77fa898_1    conda-forge\n",
            "libiconv                  1.17                 hd590300_2    conda-forge\n",
            "liblzma                   5.6.3                hb9d3cd8_1    conda-forge\n",
            "libmamba                  1.5.12               h49b8a8d_0    conda-forge\n",
            "libmambapy                1.5.12          py311hb3373dd_0    conda-forge\n",
            "libnghttp2                1.64.0               h161d5f1_0    conda-forge\n",
            "libnsl                    2.0.1                hd590300_0    conda-forge\n",
            "libsolv                   0.7.30               h3509ff9_0    conda-forge\n",
            "libsqlite                 3.47.2               hee588c1_0    conda-forge\n",
            "libssh2                   1.11.1               hf672d98_0    conda-forge\n",
            "libstdcxx                 14.2.0               hc0a3c3a_1    conda-forge\n",
            "libstdcxx-ng              14.2.0               h4852527_1    conda-forge\n",
            "libuuid                   2.38.1               h0b41bf4_0    conda-forge\n",
            "libxcrypt                 4.4.36               hd590300_1    conda-forge\n",
            "libxml2                   2.13.5               h0d44e9d_1    conda-forge\n",
            "libzlib                   1.3.1                hb9d3cd8_2    conda-forge\n",
            "lz4-c                     1.10.0               h5888daf_1    conda-forge\n",
            "lzo                       2.10              hd590300_1001    conda-forge\n",
            "mamba                     1.5.12          py311h3072747_0    conda-forge\n",
            "menuinst                  2.2.0           py311h38be061_0    conda-forge\n",
            "ncurses                   6.5                  h2d0b736_2    conda-forge\n",
            "openssl                   3.4.0                h7b32b05_1    conda-forge\n",
            "packaging                 24.2               pyhd8ed1ab_2    conda-forge\n",
            "pip                       24.3.1             pyh8b19718_2    conda-forge\n",
            "platformdirs              4.3.6              pyhd8ed1ab_1    conda-forge\n",
            "pluggy                    1.5.0              pyhd8ed1ab_1    conda-forge\n",
            "pybind11-abi              4                    hd8ed1ab_3    conda-forge\n",
            "pycosat                   0.6.6           py311h9ecbd09_2    conda-forge\n",
            "pycparser                 2.22               pyh29332c3_1    conda-forge\n",
            "pysocks                   1.7.1              pyha55dd90_7    conda-forge\n",
            "python                    3.11.11         h9e4cc4f_1_cpython    conda-forge\n",
            "python_abi                3.11                    5_cp311    conda-forge\n",
            "readline                  8.2                  h8228510_1    conda-forge\n",
            "reproc                    14.2.5.post0         hb9d3cd8_0    conda-forge\n",
            "reproc-cpp                14.2.5.post0         h5888daf_0    conda-forge\n",
            "requests                  2.32.3             pyhd8ed1ab_1    conda-forge\n",
            "ruamel.yaml               0.18.10         py311h9ecbd09_0    conda-forge\n",
            "ruamel.yaml.clib          0.2.8           py311h9ecbd09_1    conda-forge\n",
            "setuptools                65.6.3             pyhd8ed1ab_0    conda-forge\n",
            "tk                        8.6.13          noxft_h4845f30_101    conda-forge\n",
            "tqdm                      4.67.1             pyhd8ed1ab_1    conda-forge\n",
            "truststore                0.10.0             pyhd8ed1ab_0    conda-forge\n",
            "tzdata                    2024b                hc8b5060_0    conda-forge\n",
            "urllib3                   2.3.0              pyhd8ed1ab_0    conda-forge\n",
            "wheel                     0.45.1             pyhd8ed1ab_1    conda-forge\n",
            "yaml-cpp                  0.8.0                h59595ed_0    conda-forge\n",
            "zstandard                 0.23.0          py311hbc35293_1    conda-forge\n",
            "zstd                      1.5.6                ha6fb4c9_0    conda-forge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create --name env_ch5 python=3.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_t1JeM6gPzA",
        "outputId": "f9ec6776-bd65-4ca2-b36e-dc9e044ad4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.1.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/env_ch5\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.8\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2024.12.14-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h77fa898_1 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.6.3-hb9d3cd8_1 \n",
            "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.6.3-hb9d3cd8_1 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.48.0-hee588c1_1 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_2 \n",
            "  openssl            conda-forge/linux-64::openssl-3.4.0-h7b32b05_1 \n",
            "  pip                conda-forge/noarch::pip-24.3.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.8.20-h4a871b0_2_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
            "  setuptools         conda-forge/noarch::setuptools-75.3.0-pyhd8ed1ab_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_0 \n",
            "  xz                 conda-forge/linux-64::xz-5.6.3-hbcc6ac9_1 \n",
            "  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.6.3-hbcc6ac9_1 \n",
            "  xz-tools           conda-forge/linux-64::xz-tools-5.6.3-hb9d3cd8_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate env_ch5\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source deactivate base\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z0SRTQJe7KQ",
        "outputId": "0ed8baea-bcc4-475f-9d11-1e656c3a5ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeprecationWarning: 'source deactivate' is deprecated. Use 'conda deactivate'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda activate base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IWycy62jSJ9",
        "outputId": "2fa193f9-2410-4a07-9a5c-02067e4e3061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda activate env_ch5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4fTHFAiiiyt",
        "outputId": "2ed56493-afb0-4675-87cb-db7c47cff10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ3Q-wKCt3tn"
      },
      "source": [
        "## Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tq_QbrPZuib1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XKSfnq5ot3to"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "o = torch.zeros(20000).int()\n",
        "o[1152] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0T1HVuZTt3to"
      },
      "outputs": [],
      "source": [
        "E = torch.nn.Embedding(num_embeddings = 20000, embedding_dim = 300)\n",
        "e = E(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CCjtuzat3tp"
      },
      "outputs": [],
      "source": [
        "e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjVsZRcft3tp"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk94LjxOt3tp"
      },
      "source": [
        "### Embeddings in the Age of Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJTK_11zt3tp"
      },
      "source": [
        "## Embeddings in Practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc15oHXYt3tp"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kjOsr5FOt3tq"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "from torchtext import *\n",
        "import torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DKGTpHKDt3tq"
      },
      "outputs": [],
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "IKHhWz6Nt3tq",
        "outputId": "ce15878e-ec69-46f8-e6a2-fcf9f4b3ae9c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TEXT' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7997103c2bf6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glove.6B.100d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
          ]
        }
      ],
      "source": [
        "TEXT.build_vocab(train, vectors='glove.6B.100d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "WKvCMnQMt3tq",
        "outputId": "e739a9f8-5873-4d4e-ac1b-3a816a593d8c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c639b1bb47f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set up fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spacy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# TEXT = torchtext.legacy.data.Field(lower=True, include_lengths=True, batch_first=False, tokenize='spacy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# in case the tokenizer isn't picklable (e.g. spacy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchtext/data/utils.py\u001b[0m in \u001b[0;36mget_tokenizer\u001b[0;34m(tokenizer, language)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mspacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_spacy_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
          ]
        }
      ],
      "source": [
        "# set up fields\n",
        "TEXT = data.Field(lower=True, include_lengths=True, batch_first=False, tokenize='spacy')\n",
        "# TEXT = torchtext.legacy.data.Field(lower=True, include_lengths=True, batch_first=False, tokenize='spacy')\n",
        "\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# make splits for data\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "# build the vocabulary\n",
        "TEXT.build_vocab(train, vectors='glove.6B.100d') \\\n",
        "# use 'glove.42B.300d' for greater accuracy or \\\n",
        "#'glove.6B.100d' for greater speed\n",
        "LABEL.build_vocab(train)\n",
        "\n",
        "# make iterator for splits\n",
        "train_iter, test_iter = data.BucketIterator.splits((train, test), \\\n",
        "batch_sizes=(128,1024), device=dev, sort_within_batch=True, repeat=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btXruMf7t3tq"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nXZdsFst3tq"
      },
      "outputs": [],
      "source": [
        "class RNN_classifier(nn.Module):\n",
        "    def __init__(self, embedding_size = 100, hidden_size = 512, num_layers = 3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Set up an embedding layer with the right dimensions, \\\n",
        "        and copy the weights from the pretrained glove embeddings\n",
        "        vocab = TEXT.vocab\n",
        "        self.embed = nn.Embedding(len(vocab), embedding_size).cuda()\n",
        "        self.embed.weight.data.copy_(vocab.vectors)\n",
        "\n",
        "        # Set up a standard PyTorch RNN sections with the right \\\n",
        "        dimensions and a variable number of layers\n",
        "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
        "\n",
        "        # Add a two layer classification head with the right dimensions. \\\n",
        "        The final layer must output a single number\n",
        "        self.classificationLayer1 = nn.Linear(hidden_size,10)\n",
        "        self.classificationLayer2 = nn.Linear(10,1)\n",
        "\n",
        "\n",
        "    def forward(self, input, lengths=None):\n",
        "\n",
        "        embed_input = self.embed(input)\n",
        "        packed_emb = nn.utils.rnn.pack_padded_sequence(embed_input, \\\n",
        "        lengths, batch_first=False)\n",
        "\n",
        "        output, hidden = self.rnn(packed_emb)\n",
        "        hidden = hidden[-1]\n",
        "        x = hidden.squeeze(0)\n",
        "        x = self.classificationLayer1(x)\n",
        "        x = self.classificationLayer2(x)\n",
        "\n",
        "        logits = x.view(-1)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6IdKwfWt3tr"
      },
      "outputs": [],
      "source": [
        "model = RNN_classifier(hidden_size=256, num_layers=1)\n",
        "model.to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MpkM_Y1t3tr"
      },
      "outputs": [],
      "source": [
        "for batch in train_iter:\n",
        "    (x,x_len) = batch.text\n",
        "    pred = model(x,x_len)\n",
        "    print(pred.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx-KTZCKt3tr"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vevshpXat3tr"
      },
      "outputs": [],
      "source": [
        "loss_func = F.binary_cross_entropy_with_logits\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "epochs = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "374w9SnYt3tr"
      },
      "outputs": [],
      "source": [
        "def get_metrics(model, test_data):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(test_data):\n",
        "            text, text_lengths = batch_data.text\n",
        "            logits = model(text, text_lengths)\n",
        "            predicted_labels = (torch.sigmoid(logits) > 0.5).long()\n",
        "            total += batch_data.label.size(0)\n",
        "            correct += (predicted_labels == batch_data.label.long()).sum()\n",
        "        return correct.float()/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQC8OQf2t3tr"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    model.train()\n",
        "    for batch in tqdm(train_iter):\n",
        "        (x,x_lengths)=batch.text\n",
        "        pred = model(x,x_lengths)\n",
        "\n",
        "        actual=batch.label.float()\n",
        "        loss = loss_func(pred,actual)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    if (epoch==5):\n",
        "        for g in opt.param_groups:\n",
        "            g['lr'] = 3e-3\n",
        "\n",
        "    print(\"Accuracy: \" + str(get_metrics(model, test_iter).cpu().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHMtQu5Zt3ts"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br2HxW8yt3ts"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    # based on:\n",
        "    # https://github.com/bentrevett/pytorch-sentiment-analysis/blob/\n",
        "    # master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "\n",
        "    tensor = torch.LongTensor(indexed).to(dev)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOJM4N7rt3ts"
      },
      "outputs": [],
      "source": [
        "review = \"\"\"I like that Far From Home is trying something new and that its\n",
        "humor  feels more real than the ironic cracks in most superhero movies.\n",
        "I just wish its good pieces all came together more satisfyingly.\"\"\"\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk0KsxW0t3ts"
      },
      "source": [
        "## Embedding Things That Aren't Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjwlGbnHt3ts"
      },
      "source": [
        "#### A Sonnet in The MIDI Protocol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvehkoEmt3ts"
      },
      "source": [
        "### Some General Tips for Making Custom Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv-st_5vt3ts"
      },
      "source": [
        "## Conclusion"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}